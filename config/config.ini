[OLLAMA]
base_url = http://127.0.0.1:11434
model = qwen3
max_tokens = 4096
temperature = 0.0
top_p = 0.64

[MODELSCOPE]
modelscope_cache = ./model
output_dir = ./output

[OPENAI]
model = foo
max_tokens = 4096
temperature = 0.3
top_p = 0.75

[SYSTEM]
llm_mode = Ollama

