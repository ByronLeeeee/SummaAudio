import sys
import os
import streamlit as st

# Ensure the project root is in sys.path
sys.path.append(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)

from scripts.modelscope_scripts import (
    run_modelscope_recognition,
    organize_recognition_results,
    save_transcription_results,
    display_modelscope_model_selector,
)
from scripts.utils import (
    get_prompts_details,
    copy_text_to_clipboard,
    load_config_section,
    setup_logger,
    extract_and_clean_think_tags,
)
from scripts.openai_scripts import generate_openai_completion, get_openai_model_names # Stays openai_scripts
from scripts.ollama_scripts import generate_ollama_completion

logger = setup_logger("OneClickTranscriptionPage")
CACHE_DIR = "cache"

SESSION_STATE_KEYS = {
    "oc_audio_raw_text": "",
    "oc_fixed_text": "",
    "oc_summarized_text": "",
    "oc_current_audio_filename": None,
    "oc_full_transcription": "",
    "oc_speaker_transcription": "",
    "oc_fix_thoughts": "",
    "oc_summary_thoughts": "",
}
for key, default_value in SESSION_STATE_KEYS.items():
    if key not in st.session_state:
        st.session_state[key] = default_value


def cleanup_session_state():
    logger.info("Cleaning up one-click transcription session state.")
    for key in SESSION_STATE_KEYS:
        if key != "oc_current_audio_filename":
            st.session_state[key] = SESSION_STATE_KEYS[key]


def perform_text_fix(
    input_text: str, typo_prompt_template: str
) -> tuple[str, str]:
    if not input_text or not typo_prompt_template:
        return input_text, ""

    final_prompt = typo_prompt_template + "\n" + input_text
    full_raw_response = ""

    system_config = load_config_section("SYSTEM")
    llm_mode = system_config.get("llm_mode", "Ollama") # 'Ollama' or 'OpenAI'
    response_stream = None

    try:
        if llm_mode == "Ollama":
            response_stream = generate_ollama_completion(final_prompt)
        elif llm_mode == "OpenAI": # This refers to using an OpenAI-compatible API
            openai_config = load_config_section("OPENAI") # Reads [OPENAI] from config.ini
            model_name = openai_config.get("model") # Gets default model from [OPENAI]
            if not model_name:
                st.error("é»˜è®¤åœ¨çº¿æ¨¡å‹æœªåœ¨config.iniä¸­é…ç½®ã€‚è¯·å…ˆåœ¨ è®¾ç½® > åœ¨çº¿æ¨¡å‹ é¡µé¢é…ç½®ã€‚")
                return input_text, "é»˜è®¤åœ¨çº¿æ¨¡å‹æœªé…ç½®"
            
            available_online_models = get_openai_model_names() # Fetches from openai.json
            if model_name not in available_online_models:
                st.warning(f"é…ç½®çš„é»˜è®¤åœ¨çº¿æ¨¡å‹ '{model_name}' æœªåœ¨ 'config/openai.json' ä¸­æ‰¾åˆ°æˆ–å®šä¹‰ã€‚è¯·æ£€æŸ¥è®¾ç½®ã€‚")
            response_stream = generate_openai_completion(final_prompt, model_name)
        else:
            st.error(f"ä¸æ”¯æŒçš„LLMæ¨¡å¼: {llm_mode}")
            return input_text, f"ä¸æ”¯æŒçš„LLMæ¨¡å¼: {llm_mode}"

        for chunk in response_stream:
            full_raw_response += chunk

        cleaned_text, thoughts = extract_and_clean_think_tags(full_raw_response)
        return cleaned_text, thoughts
    except Exception as e:
        logger.error(f"Error in perform_text_fix: {e}")
        st.error(f"æ–‡æœ¬ä¿®æ­£æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return full_raw_response, f"æ–‡æœ¬ä¿®æ­£æ—¶å‘ç”Ÿé”™è¯¯: {e}" # Return raw response on error


def perform_summarization(
    input_text: str, summary_prompt_template: str
) -> tuple[str, str]:
    if not input_text or not summary_prompt_template:
        return input_text, ""

    final_prompt = summary_prompt_template + "\n" + input_text
    full_raw_response = ""

    system_config = load_config_section("SYSTEM")
    llm_mode = system_config.get("llm_mode", "Ollama") # 'Ollama' or 'OpenAI'
    response_stream = None

    try:
        if llm_mode == "Ollama":
            response_stream = generate_ollama_completion(final_prompt)
        elif llm_mode == "OpenAI": # This refers to using an OpenAI-compatible API
            openai_config = load_config_section("OPENAI") # Reads [OPENAI] from config.ini
            model_name = openai_config.get("model") # Gets default model from [OPENAI]
            if not model_name:
                st.error("é»˜è®¤åœ¨çº¿æ¨¡å‹æœªåœ¨config.iniä¸­é…ç½®ã€‚è¯·å…ˆåœ¨ è®¾ç½® > åœ¨çº¿æ¨¡å‹ é¡µé¢é…ç½®ã€‚")
                return input_text, "é»˜è®¤åœ¨çº¿æ¨¡å‹æœªé…ç½®"

            available_online_models = get_openai_model_names() # Fetches from openai.json
            if model_name not in available_online_models:
                st.warning(f"é…ç½®çš„é»˜è®¤åœ¨çº¿æ¨¡å‹ '{model_name}' æœªåœ¨ 'config/openai.json' ä¸­æ‰¾åˆ°æˆ–å®šä¹‰ã€‚è¯·æ£€æŸ¥è®¾ç½®ã€‚")
            response_stream = generate_openai_completion(final_prompt, model_name)
        else:
            st.error(f"ä¸æ”¯æŒçš„LLMæ¨¡å¼: {llm_mode}")
            return input_text, f"ä¸æ”¯æŒçš„LLMæ¨¡å¼: {llm_mode}"

        for chunk in response_stream:
            full_raw_response += chunk

        cleaned_text, thoughts = extract_and_clean_think_tags(full_raw_response)
        return cleaned_text, thoughts
    except Exception as e:
        logger.error(f"Error in perform_summarization: {e}")
        st.error(f"æ–‡æœ¬å½’çº³æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return full_raw_response, f"æ–‡æœ¬å½’çº³æ—¶å‘ç”Ÿé”™è¯¯: {e}" # Return raw response on error

st.header("ğŸ™ï¸ ä¸€é”®è½¬å½•ã€ä¿®æ­£ä¸å½’çº³")
st.markdown("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œåº”ç”¨å°†è‡ªåŠ¨å®Œæˆè¯­éŸ³è½¬æ–‡å­—ã€æ–‡æœ¬æ ¡å¯¹å’Œå†…å®¹æ€»ç»“ã€‚")

with st.sidebar:
    st.title("âš™ï¸ å¤„ç†é…ç½®")

    st.subheader("æ­¥éª¤ 1: è¯­éŸ³è½¬å½•")
    distinguish_speakers = st.checkbox("åŒºåˆ†è¯´è¯äºº (è‹¥æ¨¡å‹æ”¯æŒ)", value=True)
    with st.expander("é€‰æ‹©è½¬å½•æ¨¡å‹ (ModelScope)", expanded=False):
        (model_id, model_rev, vad_id, vad_rev, punc_id, punc_rev, spk_id, spk_rev) = (
            display_modelscope_model_selector()
        )

    st.subheader("æ­¥éª¤ 2: æ–‡æœ¬ä¿®æ­£ (å¯é€‰)")
    enable_fix_typo = st.checkbox("å¯ç”¨æ–‡æœ¬ä¿®æ­£", value=True)
    selected_fix_prompt_content = ""
    if enable_fix_typo:
        with st.expander("é€‰æ‹©ä¿®æ­£æç¤ºè¯", expanded=False):
            fix_prompt_list = get_prompts_details("fix_typo_prompt")
            if fix_prompt_list:
                fix_prompt_titles = [p["title"] for p in fix_prompt_list]
                selected_fix_title = st.selectbox(
                    "é€‰æ‹©ä¿®æ­£æ¨¡æ¿:", fix_prompt_titles, key="oc_fix_prompt_selector"
                )
                if selected_fix_title:
                    selected_fix_prompt_content = next(
                        (
                            p["content"]
                            for p in fix_prompt_list
                            if p["title"] == selected_fix_title
                        ),
                        "",
                    )
            else:
                st.warning("æœªæ‰¾åˆ°ä¿®æ­£æç¤ºè¯ã€‚")

    st.subheader("æ­¥éª¤ 3: å†…å®¹å½’çº³ (å¯é€‰)")
    enable_summarization = st.checkbox("å¯ç”¨å†…å®¹å½’çº³", value=True)
    selected_summary_prompt_content = ""
    if enable_summarization:
        with st.expander("é€‰æ‹©å½’çº³æç¤ºè¯", expanded=False):
            summary_mode = st.selectbox(
                "é€‰æ‹©å½’çº³ç±»å‹:", ["æ‘˜è¦", "ä¼šè®®è®°å½•"], key="oc_summary_mode_selector"
            )
            prompt_category = (
                "summary_prompt" if summary_mode == "æ‘˜è¦" else "meeting_minutes_prompt"
            )

            summary_prompt_list = get_prompts_details(prompt_category)
            if summary_prompt_list:
                summary_prompt_titles = [p["title"] for p in summary_prompt_list]
                selected_summary_title = st.selectbox(
                    f"é€‰æ‹©{summary_mode}æ¨¡æ¿:",
                    summary_prompt_titles,
                    key="oc_summary_prompt_selector",
                )
                if selected_summary_title:
                    selected_summary_prompt_content = next(
                        (
                            p["content"]
                            for p in summary_prompt_list
                            if p["title"] == selected_summary_title
                        ),
                        "",
                    )
            else:
                st.warning(f"æœªæ‰¾åˆ°{summary_mode}æç¤ºè¯ã€‚")

uploaded_audio_file = st.file_uploader(
    "ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (MP3, WAV, FLAC, M4A)",
    type=["mp3", "wav", "flac", "m4a"],
    key="oc_audio_uploader",
)

if uploaded_audio_file:
    if st.session_state.get("oc_current_audio_filename") != uploaded_audio_file.name:
        cleanup_session_state()
        st.session_state["oc_current_audio_filename"] = uploaded_audio_file.name
        logger.info(f"New audio file uploaded: {uploaded_audio_file.name}")

    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)
        logger.info(f"Cache directory created: {CACHE_DIR}")

    audio_file_path = os.path.join(CACHE_DIR, uploaded_audio_file.name)
    with open(audio_file_path, "wb") as f:
        f.write(uploaded_audio_file.getbuffer())

    st.audio(audio_file_path, format=uploaded_audio_file.type)

    if st.button("ğŸš€ å¼€å§‹ä¸€é”®å¤„ç†", type="primary", use_container_width=True):
        cleanup_session_state()
        st.session_state["oc_current_audio_filename"] = uploaded_audio_file.name

        with st.status("æ­£åœ¨è¿›è¡Œè¯­éŸ³è½¬å½•...", expanded=True) as status_transcription:
            st.write("è°ƒç”¨ModelScopeè¿›è¡Œè¯­éŸ³è¯†åˆ«...")
            try:
                if not model_id:
                    st.error("ä¸»è½¬å½•æ¨¡å‹æœªé€‰æ‹©æˆ–åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œè½¬å½•ã€‚")
                    status_transcription.update(label="è½¬å½•å¤±è´¥!", state="error")
                    st.stop()

                raw_recognition_result = run_modelscope_recognition(
                    audio_input_path=audio_file_path,
                    model_id=model_id, model_revision=model_rev,
                    vad_model_id=vad_id, vad_model_revision=vad_rev,
                    punc_model_id=punc_id, punc_model_revision=punc_rev,
                    spk_model_id=spk_id, spk_model_revision=spk_rev,
                )
                (
                    st.session_state.oc_full_transcription,
                    st.session_state.oc_speaker_transcription,
                ) = organize_recognition_results(raw_recognition_result)

                if distinguish_speakers and st.session_state.oc_speaker_transcription:
                    st.session_state.oc_audio_raw_text = (
                        st.session_state.oc_speaker_transcription
                    )
                else:
                    st.session_state.oc_audio_raw_text = (
                        st.session_state.oc_full_transcription
                    )

                if not st.session_state.oc_audio_raw_text:
                    st.warning("è¯­éŸ³è½¬å½•ç»“æœä¸ºç©ºã€‚")
                    status_transcription.update(label="è½¬å½•ç»“æœä¸ºç©ºæˆ–å¤±è´¥", state="error")
                else:
                    st.text_area(
                        "åŸå§‹è½¬å½•æ–‡æœ¬ (é¢„è§ˆ):", st.session_state.oc_audio_raw_text,
                        height=100, disabled=True, key="oc_raw_text_preview_in_status",
                    )
                    status_transcription.update(label="è¯­éŸ³è½¬å½•å®Œæˆ!", state="complete")
            except Exception as e:
                logger.error(f"Transcription error: {e}", exc_info=True)
                st.error(f"è¯­éŸ³è½¬å½•å¤±è´¥: {e}")
                status_transcription.update(label="è½¬å½•å¤±è´¥!", state="error")

        if enable_fix_typo and st.session_state.oc_audio_raw_text:
            with st.status("æ­£åœ¨ä¿®æ­£æ–‡æœ¬...", expanded=True) as status_fix:
                st.write("è°ƒç”¨LLMè¿›è¡Œæ–‡æœ¬ä¿®æ­£...")
                if not selected_fix_prompt_content:
                    st.warning("æœªé€‰æ‹©ä¿®æ­£æç¤ºè¯ï¼Œè·³è¿‡æ–‡æœ¬ä¿®æ­£ã€‚")
                    st.session_state.oc_fixed_text = st.session_state.oc_audio_raw_text
                    status_fix.update(label="ä¿®æ­£è·³è¿‡ (æ— æç¤ºè¯)", state="complete")
                else:
                    try:
                        cleaned_fixed_text, fix_thoughts = perform_text_fix(
                            st.session_state.oc_audio_raw_text, selected_fix_prompt_content,
                        )
                        st.session_state.oc_fixed_text = cleaned_fixed_text
                        st.session_state.oc_fix_thoughts = fix_thoughts

                        st.text_area(
                            "ä¿®æ­£åæ–‡æœ¬ (é¢„è§ˆ):", st.session_state.oc_fixed_text,
                            height=100, disabled=True, key="oc_fixed_text_preview_in_status",
                        )
                        if fix_thoughts:
                            with st.expander("ä¿®æ­£è¿‡ç¨‹ä¸­çš„æ€è€ƒ ğŸ¤”", expanded=False):
                                st.markdown(fix_thoughts)
                        status_fix.update(label="æ–‡æœ¬ä¿®æ­£å®Œæˆ!", state="complete")
                    except Exception as e: # Error handling already in perform_text_fix
                        st.session_state.oc_fixed_text = st.session_state.oc_audio_raw_text # Fallback
                        status_fix.update(label="æ–‡æœ¬ä¿®æ­£å¤±è´¥!", state="error")
        elif st.session_state.oc_audio_raw_text:
            st.session_state.oc_fixed_text = st.session_state.oc_audio_raw_text

        text_for_summary = st.session_state.get(
            "oc_fixed_text", st.session_state.get("oc_audio_raw_text", "")
        )
        if enable_summarization and text_for_summary:
            with st.status("æ­£åœ¨è¿›è¡Œå†…å®¹å½’çº³...", expanded=True) as status_summary:
                st.write("è°ƒç”¨LLMè¿›è¡Œå†…å®¹å½’çº³...")
                if not selected_summary_prompt_content:
                    st.warning("æœªé€‰æ‹©å½’çº³æç¤ºè¯ï¼Œè·³è¿‡å†…å®¹å½’çº³ã€‚")
                    st.session_state.oc_summarized_text = "" # Ensure it's empty if skipped
                    status_summary.update(label="å½’çº³è·³è¿‡ (æ— æç¤ºè¯)", state="complete")
                else:
                    try:
                        cleaned_summary_text, summary_thoughts = perform_summarization(
                            text_for_summary, selected_summary_prompt_content
                        )
                        st.session_state.oc_summarized_text = cleaned_summary_text
                        st.session_state.oc_summary_thoughts = summary_thoughts

                        st.text_area(
                            "å½’çº³ç»“æœ (é¢„è§ˆ):", st.session_state.oc_summarized_text,
                            height=150, disabled=True, key="oc_summary_text_preview_in_status",
                        )
                        if summary_thoughts:
                            with st.expander("å½’çº³è¿‡ç¨‹ä¸­çš„æ€è€ƒ ğŸ¤”", expanded=False):
                                st.markdown(summary_thoughts)
                        status_summary.update(label="å†…å®¹å½’çº³å®Œæˆ!", state="complete")
                    except Exception as e: # Error handling already in perform_summarization
                        status_summary.update(label="å†…å®¹å½’çº³å¤±è´¥!", state="error")
        
        if st.session_state.oc_audio_raw_text: # Save results if transcription was successful
            filename_base = os.path.splitext(uploaded_audio_file.name)[0]
            
            text_to_save_as_organized = st.session_state.oc_speaker_transcription
            mode_for_saving = "åˆ†è¯´è¯äºº"

            if enable_summarization and st.session_state.oc_summarized_text:
                text_to_save_as_organized = st.session_state.oc_summarized_text
                mode_for_saving = "å½’çº³"
            elif not distinguish_speakers or not st.session_state.oc_speaker_transcription :
                text_to_save_as_organized = st.session_state.oc_full_transcription
                mode_for_saving = "å…¨æ–‡"
            
            # Always save full transcription
            # And save "organized" text which could be speaker-separated or summary
            if save_transcription_results(
                full_text=st.session_state.oc_full_transcription,
                organized_text=text_to_save_as_organized,
                output_filename_base=filename_base,
                mode=mode_for_saving, # This mode string is just for the filename suffix of 'organized_text'
            ):
                st.success(f"å¤„ç†ç»“æœå·²ä¿å­˜åˆ° '{filename_base}' æ–‡ä»¶å¤¹ä¸­ã€‚")
            else:
                st.error("ä¿å­˜ç»“æœå¤±è´¥ã€‚")

        if os.path.exists(audio_file_path):
            try:
                os.remove(audio_file_path)
                logger.info(f"Cached audio file removed: {audio_file_path}")
            except Exception as e:
                logger.error(f"Error removing cached audio file {audio_file_path}: {e}")

        st.balloons()
        st.rerun()


st.markdown("---")
st.subheader("ğŸ“„ å¤„ç†ç»“æœé¢„è§ˆ")

if st.session_state.get("oc_audio_raw_text"):
    with st.expander("åŸå§‹è½¬å½•æ–‡æœ¬", expanded=False):
        st.text_area(
            "åŸå§‹è½¬å½•:", value=st.session_state.oc_audio_raw_text,
            height=200, disabled=True, key="disp_raw",
        )
        st.button(
            "å¤åˆ¶åŸå§‹è½¬å½•", on_click=copy_text_to_clipboard,
            args=(st.session_state.oc_audio_raw_text,), key="copy_raw",
        )

if st.session_state.get("oc_fixed_text") and enable_fix_typo : # Only show if fix was enabled
    # And ensure fixed_text is different from raw_text, or always show if enabled and process ran
    if st.session_state.oc_fixed_text != st.session_state.oc_audio_raw_text or \
       (st.session_state.oc_audio_raw_text and not selected_fix_prompt_content): # Show even if skipped if enabled
        with st.expander("ä¿®æ­£åæ–‡æœ¬", expanded=True):
            st.text_area(
                "ä¿®æ­£å:", value=st.session_state.oc_fixed_text,
                height=200, disabled=True, key="disp_fixed",
            )
            st.button(
                "å¤åˆ¶ä¿®æ­£åæ–‡æœ¬", on_click=copy_text_to_clipboard,
                args=(st.session_state.oc_fixed_text,), key="copy_fixed",
            )
            if st.session_state.get("oc_fix_thoughts"):
                with st.expander("å¯¹åº”æ€è€ƒè¿‡ç¨‹ ğŸ¤”", expanded=False):
                    st.markdown(st.session_state.oc_fix_thoughts)
                    st.button(
                        "å¤åˆ¶ä¿®æ­£æ€è€ƒè¿‡ç¨‹", on_click=copy_text_to_clipboard,
                        args=(st.session_state.oc_fix_thoughts,), key="copy_oc_fix_thoughts",
                    )

if st.session_state.get("oc_summarized_text") and enable_summarization: # Only show if summarization was enabled
    with st.expander("å½’çº³ç»“æœ", expanded=True):
        st.text_area(
            "å½’çº³:", value=st.session_state.oc_summarized_text,
            height=250, disabled=True, key="disp_summary",
        )
        st.button(
            "å¤åˆ¶å½’çº³ç»“æœ", on_click=copy_text_to_clipboard,
            args=(st.session_state.oc_summarized_text,), key="copy_summary",
        )
        if st.session_state.get("oc_summary_thoughts"):
            with st.expander("å¯¹åº”æ€è€ƒè¿‡ç¨‹ ğŸ¤”", expanded=False):
                st.markdown(st.session_state.oc_summary_thoughts)
                st.button(
                    "å¤åˆ¶å½’çº³æ€è€ƒè¿‡ç¨‹", on_click=copy_text_to_clipboard,
                    args=(st.session_state.oc_summary_thoughts,), key="copy_oc_summary_thoughts",
                )